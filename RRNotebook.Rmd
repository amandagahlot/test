---
title: "R Notebook"
author: "Amanda Gahlot"
date: "2024_10_05"
output:
  html_document:
    toc: true
    toc_float: true
  pdf_document:
    toc: true
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 

# 1. Set Up

This section reviews how to set up your Notebook. We will review headings for the table of contents, how to print code and/or output, and knit options.

## 1.1 Headings

Headings are created using hashtags and a space between the hastags and the words. 

## 1.2 Formatting

You can format text using Markdown:
- *Italics*: Use single asterisks `*italic text*` or underscores `_italic text_`.
- **Bold**: Use double asterisks `**bold text**` or underscores `__bold text__`.
- ***Bold Italics***: Use triple asterisks `***bold italic text***`.
- > **Blockquotes**: Use `>` before text to create an indented block.

To insert a **horizontal line** (separator), use three or more dashes `---` or asterisks `***`.

## 1.3 Knit Options

In R Markdown, you can customize how each code chunk behaves using chunk options. These options control whether the code, results, or any messages or warnings are displayed. Here are some commonly used chunk options:

***echo***: Controls whether the code itself is displayed in the output.

echo=TRUE (default): Show the code.
echo=FALSE: Hide the code but show the output.

***include***: Controls whether the code and the results are included in the output.

include=TRUE (default): Include both code and results.
include=FALSE: Exclude both code and results (useful for running code without showing it).

***results***: Controls how the output is displayed.

results='markup' (default): Show the usual output.
results='asis': Interpret the output as raw Markdown/HTML (useful for creating tables).
results='hide': Hide the results, but still execute the code.

***message and warning***: Controls whether messages and warnings generated by the code are displayed.

message=TRUE (default): Show messages.
message=FALSE: Hide messages.
warning=TRUE (default): Show warnings.
warning=FALSE: Hide warnings.

***fig.show***: Controls whether figures generated by the code chunk are displayed.

fig.show='asis': Shows figures inline.
fig.show='hide': Suppresses figure output.
fig.height and fig.width: Set the height and width of the figures generated by the chunk.

---
**So as an example:** 
{r knit option 1, echo=FALSE, include=TRUE, results='asis'} would exclude the actual code but would include the output with the results as they should be (great for visuals and tables). 


You can set a default of options for your entire notebook so you don't have to type it in each time. If you want to deviate from that setting, you just type in the extra options. 

```{r prelims}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
#now no error or warning messages will show when I knit this document. Note that I did not need to enter echo=TRUE or results=TRUE because those are already default settings. 
```

If i wanted a chunk of code to not knit either results or code, I could change it in the {r} section: {r, echo=FALSE, results=FALSE}

***PRO TIP***
When you try to knit something and get this error:

*Error in parse_block(g[-1], g[1], params.src, markdown_mode) : 
  Duplicate chunk label 'set wd', which has been used for the chunk:
setwd("/Users/amandagahlot/Documents/Dissertation/R_Output")
Calls: <Anonymous> ... process_file -> split_file -> lapply -> FUN -> parse_block
Execution halted*

This is because you need to have a unique name for each of your code blocks: {r something unique} 

# 2. Import data

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.


```{r chunk code}
#you can load all of your libraries with one click. 

#libraries
library(tidyverse)
library(psych)
library(data.table)
library(sjPlot) 
library(sjmisc) 
library(sjlabelled) 
library(gtsummary)
library(readxl)
```

First, set your working directory (save time, save sanity)

```{r set wd, echo=FALSE}
setwd("/Users/amandagahlot/test")
```

## RedCAP

Option 1: You can do this directly from RedCAP **if** you have API option in RedCAP. If so, follow these steps: https://cran.r-project.org/web/packages/tidyREDCap/vignettes/useAPI.html
***Note that you never want to put your API token directly into your R code***

Option 2: Export data from RedCAP *using raw data not labels* into CSV file and either work from there or save as excel file. 

## GitHub

Steps

Go to the github repository link where you have the CSV file

Click on the raw option present on the top right of the data

This will open a new window in the browser

The link should be like https://raw.githubusercontent.com/..

You have to use this link to download csv file from the Github

```{r, results='hide'}
library (readr)

urlfile="https://raw.githubusercontent.com/keithlohse/ReproRehab/refs/heads/main/data/data_PROCESSED_EEG.csv"

keith_data<-read_csv(url(urlfile))
```
## Computer
 
```{r import data, results='hide'}

df <- read_excel('cleaned_data_Final.xlsx')

print(head(df))
```

# 3. Data cleaning
The best book I've used for understanding data cleaning and wrangling is: **R for Data Science** https://r4ds.had.co.nz/

## tidyverse

The tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. Tidyverse includes packages such as: *ggplot, tibble, forcats, readr, stringr, purr, and dplyr*

Introduction to tidyverse: https://www.tidyverse.org/packages/

Citation for tidyverse:
Wickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L., R., F., Grolemund, G., Hayes, A., Henry, L., Kuhn, H., Pederson, T., Miller, E., Bache, S., Muller, K., Ooms, J., Robinson, D., Seidel, D., Spinu, V., Takahashi, K., . . . Yutani, H. (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686. https://doi.org/doi:10.21105/joss.01686 


```{r tidyverse}

#install(tidyverse)
#library(tidyverse)
```


## dplyr

dplyr is a grammar of data manipulation, providing a consistent set of verbs that help you solve the most common data manipulation challenges

Cheat Sheet for dplyr/tidyverse: https://www.rstudio.com/wp-content%2Fuploads%2F2015%2F02%2Fdata-wrangling-cheatsheet.pdf%2F



```{r}
#mutate() adds new variables that are functions of existing variables
#select() picks variables based on their names.
#filter() picks cases based on their values.
#summarise() reduces multiple values down to a single summary.
#arrange() changes the ordering of the rows.
```
```{r mutate, results='hide'}
#mutate (df, new_variable = existing_var*2)

#below we're going to create two new variables, the first uses piping to add five individuals scores into a total score

df <- df %>%
  mutate(bfi_total = bfi_openness + bfi_extraversion + bfi_neuroticism + 
                   bfi_consciousness + bfi_agreeable)

#OR without piping, you can use this code and here we're only choosing the personality types associated with happiness

df <- mutate(df, bfi_happy = bfi_openness + bfi_extraversion + bfi_agreeable)

```


```{r, results='hide'}

#To see just one variable, you can select either with or without piping
#select(df, variable_name)

df %>% select(bfi_total)

select(df, bfi_total)
```
```{r filter, results='hide'}

#Now we can start to combine these data wrangling functions. Here I only want results for those people who are really happy. I can filter from the selected variable. 

df %>%
  filter(bfi_happy > 20) %>%
  select(bfi_happy)
#or without piping

filtered_df <- filter(df, bfi_happy > 20)
selected_df <- select(filtered_df, bfi_happy)
```
The summarise function is fun. It can:

Condense data: Summarise large datasets into more manageable, aggregated results.

Perform group-wise calculations: When used with group_by(), it lets you compute statistics for each group in the data (e.g., mean score for each age group).

Efficiency: It's built for fast aggregation and calculation on large datasets.

Readability: Simplifies code by avoiding more complex for loops.

```{r summarise}
df %>%
  group_by(gender) %>%
  summarise(mean_bfi_happy = mean(bfi_happy, na.rm = TRUE))
```

Uh oh, that gender variable is not helpful. Let's change it using our codebook 

```{r gender rename}
df$gender <- factor(df$gender,
                   levels = c(1,2,3),
                   labels = c("Male", "Female", "Nonbinary"))
```

.... and try again. I also want to round to the 3rd decimal place as the rounded answer was the same...

```{r gender by happiness}
df %>%
  group_by(gender) %>%
  summarise(mean_bfi_happy = round(mean(bfi_happy, na.rm = TRUE), 3))
```
### Piping

Piping is a programming technique that allows you to pass the output of one function directly as the input to another function, creating a seamless flow of data transformation. In R, the most commonly used piping operator is %>%, which is provided by the _magrittr_ package and is also included in the _dplyr_ package as part of the tidyverse ecosystem.

How Piping Works:
When you use the pipe operator %>%, it takes the output of the expression on its left and "pipes" it into the function on its right. This makes the code more readable and intuitive, as it flows from one operation to the next in a left-to-right manner.

## Outliers
Searching for outliers before analyzing data is important because outliers can significantly affect your results and interpretations.

We can find outliers using descriptive statistics and with visualizations

```{r outliers_stats, results='asis'}
summary_stats <- describeBy(df) %>% round(2)

# Display the summary statistics using kable
knitr::kable(summary_stats)
```
```{r vis outliers}
#create a function first, then we can add in any variables we want to see if there are outliers

plot_hist_box <- function(df, var) {
  # Load required package
  library(ggplot2)
  
  # Create a histogram
  p1 <- ggplot(df, aes_string(x = var)) +
    geom_histogram(binwidth = 1, color = "black", fill = "lightblue") +
    labs(title = paste("Histogram of", var), x = var, y = "Frequency")
  
  # Create a vertical boxplot
  p2 <- ggplot(df, aes_string(y = var)) +  # 'y' instead of 'x' for vertical
    geom_boxplot(fill = "lightgreen") +
    labs(title = paste("Boxplot of", var), y = var, x = "")  # Empty x label
  
  # Print the plots side by side
  gridExtra::grid.arrange(p1, p2, ncol = 2)
}

# Example usage:
plot_hist_box(df, "bfi_happy")


```
```{r function fun}
# now we can apply that function to any variable easily

plot_hist_box(df, 'frsbe_apathy')

#functions can be helpful because
```
*Reference for ggplot2:
Wickham, H., Chang, W., & Wickham, M. H. (2016). Package ‘ggplot2’. Create elegant data visualisations using the grammar of graphics. Version, 2(1), 1-189.* 

### Fun with Functions
Using functions in R (or any programming language) offers several key benefits beyond just making the code shorter and cleaner. Here are some of the primary advantages:

Reusability: Functions allow you to write a block of code once and reuse it multiple times throughout your script or across different scripts. This reduces redundancy and minimizes the risk of errors since you only need to update the function in one place if changes are needed.

Modularity: Functions break down complex problems into smaller, manageable pieces. This modular approach makes it easier to understand and debug your code, as you can focus on one function at a time without being overwhelmed by the entire program.

Readability and Clarity: Functions can improve the readability of your code by providing meaningful names that describe what the function does. This makes it easier for others (or yourself in the future) to understand the logic and purpose of your code.

Abstraction: Functions can encapsulate complex operations, allowing users to interact with a simple interface while hiding the underlying complexity. This abstraction simplifies code usage, making it accessible to those who may not need to understand the details.

Testing and Debugging: Functions make it easier to isolate and test specific parts of your code. You can test individual functions independently to ensure they work correctly before integrating them into larger workflows.

Consistency: Using functions can help maintain consistency in your analyses. When you apply the same function to similar data structures or processes, you’re more likely to get consistent results.

Parameterization: Functions can accept arguments, allowing you to customize their behavior without modifying the function's internal code. This flexibility enables you to adapt the function to different datasets or conditions without rewriting code.

Performance: In some cases, functions can improve performance by optimizing specific operations. For instance, vectorized operations in R can be implemented in functions to leverage R's efficient handling of vectors and matrices.

To learn more:

https://www.datacamp.com/tutorial/functions-in-r-a-tutorial

https://r4ds.hadley.nz/functions.html


### Handling outliers

If a value was entered incorrectly, we can just fix it....

Found that record 001 was incorrectly entered as 270 and I want to change to the correct response of 27

```{r fixing}
df$frsbe_apathy[df$record_id == "001"] <- 27

#check the updated value
df[df$record_id == "001", c("record_id", "frsbe_apathy")]

```
If the value is correct, but is skewing everything up...

```{r find it}
#first we have to find the record/ID

# Display record_id and bfi_happiness scores
associated_records <- df %>%
  select(record_id, bfi_happy)

# View the results
print(associated_records)

```
or....
```{r}
# Find record_id where bfi_happiness <10
outlier_bfi_happy_records <- df %>%
  filter(bfi_happy < 10) %>%
  select(record_id, bfi_happy)

# View the results
print(outlier_bfi_happy_records)

```
Then create a new data frame that drops those outliers. Then you can do any future analysis on df_happy when appropriate, but use df when df_happy isn't involved

```{r df_happy}
df_happy <- df %>%
  filter(!record_id %in% c("011", "058"))
```

## Save clean file

I do all of my data cleaning and wrangling in a different Notebook than my analysis. Find a workflow that works for you, but it keeps it easier for me with less errors as packages start to overlap. It also keeps you from having to go back and re-clean everytime you want to do a new analysis

```{r save clean file}
#install needed package
#install.packages("writexl")
library("writexl")

#export df_happy to an excel file
write_xlsx(df_happy, "df_cleaned.xlsx")

```




When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file). 

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

